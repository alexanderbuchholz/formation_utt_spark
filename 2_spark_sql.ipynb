{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark and SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Useful ressources: \n",
    "* https://www.tutorialspoint.com/spark_sql/spark_sql_quick_guide.htm\n",
    "* https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id='123456', name='Computer Science')\n",
      "Row(firstName='xiangrui', lastName='meng', email='no-reply@stanford.edu', salary=120000)\n",
      "no-reply@berkeley.edu\n"
     ]
    }
   ],
   "source": [
    "# import pyspark class Row from module sql\n",
    "from pyspark.sql import *\n",
    "\n",
    "# Create Example Data - Departments and Employees\n",
    "\n",
    "# Create the Departments\n",
    "department1 = Row(id='123456', name='Computer Science')\n",
    "department2 = Row(id='789012', name='Mechanical Engineering')\n",
    "department3 = Row(id='345678', name='Theater and Drama')\n",
    "department4 = Row(id='901234', name='Indoor Recreation')\n",
    "\n",
    "# Create the Employees\n",
    "Employee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\n",
    "employee1 = Employee('michael', 'armbrust', 'no-reply@berkeley.edu', 100000)\n",
    "employee2 = Employee('xiangrui', 'meng', 'no-reply@stanford.edu', 120000)\n",
    "employee3 = Employee('matei', None, 'no-reply@waterloo.edu', 140000)\n",
    "employee4 = Employee(None, 'wendell', 'no-reply@berkeley.edu', 160000)\n",
    "\n",
    "# Create the DepartmentWithEmployees instances from Departments and Employees\n",
    "departmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2])\n",
    "departmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4])\n",
    "departmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4])\n",
    "departmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])\n",
    "\n",
    "print department1\n",
    "print employee2\n",
    "print departmentWithEmployees1.employees[0].email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SQLContext\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataFrames from a list of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          department|           employees|\n",
      "+--------------------+--------------------+\n",
      "|[123456, Computer...|[[michael, armbru...|\n",
      "|[789012, Mechanic...|[[matei,, no-repl...|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|          department|           employees|\n",
      "+--------------------+--------------------+\n",
      "|[345678, Theater ...|[[michael, armbru...|\n",
      "|[901234, Indoor R...|[[xiangrui, meng,...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departmentsWithEmployeesSeq1 = [departmentWithEmployees1, departmentWithEmployees2]\n",
    "df1 = sqlContext.createDataFrame(departmentsWithEmployeesSeq1)\n",
    "\n",
    "df1.show()\n",
    "        \n",
    "departmentsWithEmployeesSeq2 = [departmentWithEmployees3, departmentWithEmployees4]\n",
    "df2 = sqlContext.createDataFrame(departmentsWithEmployeesSeq2)\n",
    "\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with DataFrames\n",
    "## Union two DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          department|           employees|\n",
      "+--------------------+--------------------+\n",
      "|[123456, Computer...|[[michael, armbru...|\n",
      "|[789012, Mechanic...|[[matei,, no-repl...|\n",
      "|[345678, Theater ...|[[michael, armbru...|\n",
      "|[901234, Indoor R...|[[xiangrui, meng,...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unionDF = df1.unionAll(df2)\n",
    "unionDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the unioned DataFrame to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the file if it exists\n",
    "unionDF.write.parquet(\"./databricks-df-example.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a DataFrame from the Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          department|           employees|\n",
      "+--------------------+--------------------+\n",
      "|[345678, Theater ...|[[michael, armbru...|\n",
      "|[123456, Computer...|[[michael, armbru...|\n",
      "|[789012, Mechanic...|[[matei,, no-repl...|\n",
      "|[901234, Indoor R...|[[xiangrui, meng,...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquetDF = sqlContext.read.parquet(\"./databricks-df-example.parquet\")\n",
    "parquetDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explode the employees column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "|    matei|    null|no-reply@waterloo...|140000|\n",
      "|     null| wendell|no-reply@berkeley...|160000|\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "|     null| wendell|no-reply@berkeley...|160000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "|    matei|    null|no-reply@waterloo...|140000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df = unionDF.select(explode(\"employees\").alias(\"e\"))\n",
    "explodeDF = df.selectExpr(\"e.firstName\", \"e.lastName\", \"e.email\", \"e.salary\")\n",
    "\n",
    "explodeDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use filter() to return the rows that match a predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filterDF = explodeDF.filter(explodeDF.firstName == \"xiangrui\").sort(explodeDF.lastName)\n",
    "filterDF.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, asc\n",
    "\n",
    "# Use `|` instead of `or`\n",
    "filterDF = explodeDF.filter((col(\"firstName\") == \"xiangrui\") | (col(\"firstName\") == \"michael\")).sort(asc(\"lastName\"))\n",
    "filterDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The where() clause is equivalent to filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "whereDF = explodeDF.where((col(\"firstName\") == \"xiangrui\") | (col(\"firstName\") == \"michael\")).sort(asc(\"lastName\"))\n",
    "whereDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace null values with -- using DataFrame Na function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "|    matei|      --|no-reply@waterloo...|140000|\n",
      "|       --| wendell|no-reply@berkeley...|160000|\n",
      "|  michael|armbrust|no-reply@berkeley...|100000|\n",
      "|       --| wendell|no-reply@berkeley...|160000|\n",
      "| xiangrui|    meng|no-reply@stanford...|120000|\n",
      "|    matei|      --|no-reply@waterloo...|140000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nonNullDF = explodeDF.fillna(\"--\")\n",
    "nonNullDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve only rows with missing firstName or lastName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+\n",
      "|firstName|lastName|               email|salary|\n",
      "+---------+--------+--------------------+------+\n",
      "|     null| wendell|no-reply@berkeley...|160000|\n",
      "|     null| wendell|no-reply@berkeley...|160000|\n",
      "|    matei|    null|no-reply@waterloo...|140000|\n",
      "|    matei|    null|no-reply@waterloo...|140000|\n",
      "+---------+--------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filterNonNullDF = explodeDF.filter(col(\"firstName\").isNull() | col(\"lastName\").isNull()).sort(\"email\")\n",
    "filterNonNullDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example aggregations using agg() and countDistinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------------------------+\n",
      "|firstName|lastName|count(DISTINCT firstName)|\n",
      "+---------+--------+-------------------------+\n",
      "|     null| wendell|                        0|\n",
      "|    matei|    null|                        1|\n",
      "| xiangrui|    meng|                        1|\n",
      "|  michael|armbrust|                        1|\n",
      "+---------+--------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "countDistinctDF = explodeDF.select(\"firstName\", \"lastName\")\\\n",
    "  .groupBy(\"firstName\", \"lastName\")\\\n",
    "  .agg(countDistinct(\"firstName\"))\n",
    "\n",
    "countDistinctDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the DataFrame and SQL query physical plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) HashAggregate(keys=[firstName#61, lastName#62], functions=[count(distinct firstName#61)])\n",
      "+- *(4) HashAggregate(keys=[firstName#61, lastName#62], functions=[partial_count(distinct firstName#61)])\n",
      "   +- *(4) HashAggregate(keys=[firstName#61, lastName#62, firstName#61], functions=[])\n",
      "      +- Exchange hashpartitioning(firstName#61, lastName#62, firstName#61, 200)\n",
      "         +- *(3) HashAggregate(keys=[firstName#61, lastName#62, firstName#61], functions=[])\n",
      "            +- *(3) Project [e#59.firstName AS firstName#61, e#59.lastName AS lastName#62]\n",
      "               +- Generate explode(employees#1), false, [e#59]\n",
      "                  +- Union\n",
      "                     :- *(1) Project [employees#1]\n",
      "                     :  +- Scan ExistingRDD[department#0,employees#1]\n",
      "                     +- *(2) Project [employees#13]\n",
      "                        +- Scan ExistingRDD[department#12,employees#13]\n",
      "== Physical Plan ==\n",
      "*(4) HashAggregate(keys=[firstName#61, lastName#62], functions=[count(distinct firstName#61)])\n",
      "+- *(4) HashAggregate(keys=[firstName#61, lastName#62], functions=[partial_count(distinct firstName#61)])\n",
      "   +- *(4) HashAggregate(keys=[firstName#61, lastName#62, firstName#61], functions=[])\n",
      "      +- Exchange hashpartitioning(firstName#61, lastName#62, firstName#61, 200)\n",
      "         +- *(3) HashAggregate(keys=[firstName#61, lastName#62, firstName#61], functions=[])\n",
      "            +- *(3) Project [e#59.firstName AS firstName#61, e#59.lastName AS lastName#62]\n",
      "               +- Generate explode(employees#1), false, [e#59]\n",
      "                  +- Union\n",
      "                     :- *(1) Project [employees#1]\n",
      "                     :  +- Scan ExistingRDD[department#0,employees#1]\n",
      "                     +- *(2) Project [employees#13]\n",
      "                        +- Scan ExistingRDD[department#12,employees#13]\n"
     ]
    }
   ],
   "source": [
    "countDistinctDF.explain()\n",
    "# register the DataFrame as a temp table so that we can query it using SQL\n",
    "explodeDF.registerTempTable(\"databricks_df_example\")\n",
    "\n",
    "# Perform the same query as the DataFrame above and return ``explain``\n",
    "countDistinctDF_sql = sqlContext.sql(\"SELECT firstName, lastName, count(distinct firstName) as distinct_first_names FROM databricks_df_example GROUP BY firstName, lastName\")\n",
    "\n",
    "countDistinctDF_sql.explain()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum up all the salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|    1040000|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salarySumDF = explodeDF.agg({\"salary\" : \"sum\"})\n",
    "salarySumDF.show()\n",
    "\n",
    "type(explodeDF.salary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the summary statistics for the salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            salary|\n",
      "+-------+------------------+\n",
      "|  count|                 8|\n",
      "|   mean|          130000.0|\n",
      "| stddev|23904.572186687874|\n",
      "|    min|            100000|\n",
      "|    max|            160000|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explodeDF.describe(\"salary\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example using pandas and Matplotlib integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEkCAYAAADTtG33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "pdDF = nonNullDF.toPandas()\n",
    "pdDF.plot(x='firstName', y='salary', kind='bar', rot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also for more information: \n",
    "* https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html\n",
    "* https://spark.apache.org/docs/latest/sql-programming-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "u'Path does not exist: file:/FileStore/tables/movies.csv;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5d1de75f107c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# sql import of the movies and rating data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inferschema\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DROPMALFORMED\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/FileStore/tables/movies.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inferschema\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DROPMALFORMED\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/FileStore/tables/ratings.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcountDistinct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/pyspark/sql/readwriter.pyc\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u'Path does not exist: file:/FileStore/tables/movies.csv;'"
     ]
    }
   ],
   "source": [
    "# sql import of the movies and rating data\n",
    "movies = sqlContext.read.option(\"inferschema\", \"true\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(\"/FileStore/tables/movies.csv\")\n",
    "\n",
    "ratings = sqlContext.read.option(\"inferschema\", \"true\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(\"/FileStore/tables/ratings.csv\")\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "from pyspark.sql.functions import countDistinct, min, max\n",
    "print movies.select(\"movieId\")\\\n",
    "  .agg(countDistinct(\"movieId\")).collect()\n",
    "\n",
    "print ratings.select(\"rating\")\\\n",
    "  .agg(min(\"rating\")).collect()\n",
    "\n",
    "print ratings.select(\"rating\")\\\n",
    "  .agg(max(\"rating\")).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
